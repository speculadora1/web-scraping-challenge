{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup mongo connection\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish database\n",
    "db = client.mission_to_mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up splinter\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "\n",
    "# create bs object; parse with html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all div with class slide, store them in result set\n",
    "results = soup.find_all('div', class_ = 'slide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "NASA Prepares for Moon and Mars With New Addition to Its Deep Space Network\n",
      "Robotic spacecraft will be able to communicate with the dish using radio waves and lasers.\n",
      "-----------------\n",
      "NASA Administrator Statement on Moon to Mars Initiative, FY 2021 Budget\n",
      "Jim Bridenstine addresses NASA's ambitious plans for the coming years, including Mars Sample Return.\n",
      "-----------------\n",
      "NASA's Mars 2020 Rover Closer to Getting Its Name\n",
      "155 students from across the U.S. have been chosen as semifinalists in NASA's essay contest to name the Mars 2020 rover, and see it launch from Cape Canaveral this July.\n",
      "-----------------\n",
      "NASA Invites Students to Name Mars 2020 Rover\n",
      "Through Nov. 1, K-12 students in the U.S. are encouraged to enter an essay contest to name NASA's next Mars rover.\n",
      "-----------------\n",
      "NASA's Curiosity Mars Rover Finds a Clay Cache\n",
      "The rover recently drilled two samples, and both showed the highest levels of clay ever found during the mission.\n",
      "-----------------\n",
      "Why This Martian Full Moon Looks Like Candy\n",
      "For the first time, NASA's Mars Odyssey orbiter has caught the Martian moon Phobos during a full moon phase. Each color in this new image represents a temperature range detected by Odyssey's infrared camera.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1174ecc88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty list to store dictionaries\n",
    "mars_news = []\n",
    "\n",
    "# loop through all slides, store relevant content\n",
    "for result in results:\n",
    "    \n",
    "    # create empty dict to store article data\n",
    "    article_data = {}\n",
    "    \n",
    "    # scrape article title\n",
    "    title = result.find('div', class_='content_title').text\n",
    "    # remove leading/trailing spaces\n",
    "    title = title.strip()\n",
    "    \n",
    "    # scrape article description\n",
    "    desc = result.find('div', class_='rollover_description_inner').text\n",
    "    # remove leading/trailing spaces\n",
    "    desc = desc.strip()\n",
    "    \n",
    "    # print article data\n",
    "    print('-----------------')\n",
    "    print(title)\n",
    "    print(desc)\n",
    "    \n",
    "    # store data in dictionary to be appended to list\n",
    "    article_data = {\n",
    "        'news_title': title,\n",
    "        'news_p': desc\n",
    "    }\n",
    "    \n",
    "    mars_news.append(article_data)\n",
    "\n",
    "# drop existing collection\n",
    "db.news.drop()\n",
    "\n",
    "# insert data\n",
    "db.news.insert_many(mars_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url to scrape image\n",
    "base_url = 'https://www.jpl.nasa.gov'\n",
    "img_search_url = f'{base_url}/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# use splinter to visit url\n",
    "browser.visit(img_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set html from browser\n",
    "html = browser.html\n",
    "\n",
    "# create soup object, parse with html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x1174ecec8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find anchor with image link\n",
    "results = soup.find_all('a', class_='button fancybox')\n",
    "\n",
    "# find href from result\n",
    "img_href = results[0]['data-fancybox-href']\n",
    "\n",
    "# build url from href and base url\n",
    "featured_img_url = f'{base_url}{img_href}'\n",
    "\n",
    "# drop existing collection\n",
    "db.featured.drop()\n",
    "\n",
    "# insert data\n",
    "db.featured.insert_one({\"featured_img_url\": featured_img_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of twitter page to scrape\n",
    "twitter = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# retrieve page with the requests module\n",
    "response = requests.get(twitter)\n",
    "\n",
    "# create bs object; parse with html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x1176ebcc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all div with class js-tweet-text-container, store them in result set\n",
    "results = soup.find_all('div', class_ = 'js-tweet-text-container')\n",
    "\n",
    "# get the top result (most recent tweet), and pull the text inside the paragraph element\n",
    "mars_weather = results[0].find('p').text\n",
    "\n",
    "# split the string on the start of the image link to remove it\n",
    "mars_weather = mars_weather.split('pic.twitter.com')[0]\n",
    "\n",
    "# drop existing collection\n",
    "db.weather.drop()\n",
    "\n",
    "# insert data\n",
    "db.weather.insert_one({'weather': mars_weather})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of facts page to scrape\n",
    "space_facts = 'https://space-facts.com/mars/'\n",
    "\n",
    "# retrieve page with the requests module\n",
    "response = requests.get(space_facts)\n",
    "\n",
    "# create bs object; parse with html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all tables, store them in result set\n",
    "results = soup.find_all('table')\n",
    "\n",
    "# get the top result, and read the data into a pandas table\n",
    "table = results[0]\n",
    "\n",
    "table = pd.read_html(str(table))\n",
    "\n",
    "# read_html returns a list, use index to store the table as a df\n",
    "mars_facts = table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x106b87c48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to html code for table\n",
    "html_code = mars_facts.to_html(header = False, index = False)\n",
    "\n",
    "# replace table wrapper so bootstrap table can be used\n",
    "html_code = html_code.replace('<table border=\"1\" class=\"dataframe\">', '')\n",
    "html_code = html_code.replace('</table>', '')\n",
    "\n",
    "# drop existing collection\n",
    "db.facts.drop()\n",
    "\n",
    "# insert data\n",
    "db.facts.insert_one({'html_code': html_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/speculadora/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/splinter/driver/webdriver/__init__.py:504: FutureWarning: browser.find_link_by_partial_text is deprecated. Use browser.links.find_by_partial_text instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# create list of hemisphere names\n",
    "hemispheres = ['Cerberus',\n",
    "              'Schiaparelli',\n",
    "              'Syrtis Major',\n",
    "              'Valles Marineris']\n",
    "\n",
    "# initialize list to store all hemisphere data\n",
    "hemisphere_data = []\n",
    "\n",
    "for hemisphere in hemispheres:\n",
    "        \n",
    "    # intialize dictionary to store individual hemisphere data\n",
    "    current_hemisphere = {}\n",
    "    \n",
    "    # set starting point\n",
    "    hemisphere_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "    # use splinter to visit url\n",
    "    browser.visit(hemisphere_url)\n",
    "    \n",
    "    # navigate to hemisphere page\n",
    "    browser.click_link_by_partial_text(hemisphere)\n",
    "\n",
    "    # set html from browser\n",
    "    html = browser.html\n",
    "\n",
    "    # create soup object, parse with html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # find div that contains image link, remove it from list\n",
    "    results = soup.find('div', class_ = 'wide-image-wrapper')\n",
    "\n",
    "    # pull the href from the first anchor inside the div to get image link\n",
    "    img_url = results.find('a')['href']\n",
    "    \n",
    "    # find div that contains page title\n",
    "    results = soup.find('div', class_ = 'content')\n",
    "\n",
    "    # pull the text from the header\n",
    "    long_title = results.find('h2').text\n",
    "\n",
    "    # remove 'Enhanced' or 'Unenhanced' from the text\n",
    "    title = long_title.replace(' Enhanced', '')\n",
    "    \n",
    "    # add data to dictionary\n",
    "    current_hemisphere['title'] = title\n",
    "    current_hemisphere['img_url'] = img_url\n",
    "    \n",
    "    hemisphere_data.append(current_hemisphere)\n",
    "    \n",
    "# drop existing collection\n",
    "db.hemispheres.drop()\n",
    "\n",
    "# insert data\n",
    "db.hemispheres.insert_many(hemisphere_data)\n",
    "\n",
    "# quit chrome\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
