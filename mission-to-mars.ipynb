{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "\n",
    "# create bs object; parse with html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all div with class slide, store them in result set\n",
    "results = soup.find_all('div', class_ = 'slide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "NASA Prepares for Moon and Mars With New Addition to Its Deep Space Network\n",
      "Robotic spacecraft will be able to communicate with the dish using radio waves and lasers.\n",
      "-----------------\n",
      "NASA Administrator Statement on Moon to Mars Initiative, FY 2021 Budget\n",
      "Jim Bridenstine addresses NASA's ambitious plans for the coming years, including Mars Sample Return.\n",
      "-----------------\n",
      "NASA's Mars 2020 Rover Closer to Getting Its Name\n",
      "155 students from across the U.S. have been chosen as semifinalists in NASA's essay contest to name the Mars 2020 rover, and see it launch from Cape Canaveral this July.\n",
      "-----------------\n",
      "NASA Invites Students to Name Mars 2020 Rover\n",
      "Through Nov. 1, K-12 students in the U.S. are encouraged to enter an essay contest to name NASA's next Mars rover.\n",
      "-----------------\n",
      "NASA's Curiosity Mars Rover Finds a Clay Cache\n",
      "The rover recently drilled two samples, and both showed the highest levels of clay ever found during the mission.\n",
      "-----------------\n",
      "Why This Martian Full Moon Looks Like Candy\n",
      "For the first time, NASA's Mars Odyssey orbiter has caught the Martian moon Phobos during a full moon phase. Each color in this new image represents a temperature range detected by Odyssey's infrared camera.\n"
     ]
    }
   ],
   "source": [
    "# create empty list to store dictionaries\n",
    "mars_news = []\n",
    "\n",
    "# loop through all slides, store relevant content\n",
    "for result in results:\n",
    "    \n",
    "    # create empty dict to store article data\n",
    "    article_data = {}\n",
    "    \n",
    "    # scrape article title\n",
    "    title = result.find('div', class_='content_title').text\n",
    "    # remove leading/trailing spaces\n",
    "    title = title.strip()\n",
    "    \n",
    "    # scrape article description\n",
    "    desc = result.find('div', class_='rollover_description_inner').text\n",
    "    # remove leading/trailing spaces\n",
    "    desc = desc.strip()\n",
    "    \n",
    "    # print article data\n",
    "    print('-----------------')\n",
    "    print(title)\n",
    "    print(desc)\n",
    "    \n",
    "    # store data in dictionary to be appended to list\n",
    "    article_data = {\n",
    "        'news_title': title,\n",
    "        'news_p': desc\n",
    "    }\n",
    "    \n",
    "    mars_news.append(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url to scrape image\n",
    "base_url = 'https://www.jpl.nasa.gov'\n",
    "img_search_url = f'{base_url}/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# use splinter to visit url\n",
    "browser.visit(img_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set html from browser\n",
    "html = browser.html\n",
    "\n",
    "# create soup object, parse with html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find anchor with image link\n",
    "results = soup.find_all('a', class_='button fancybox')\n",
    "\n",
    "# find href from result\n",
    "img_href = results[0]['data-fancybox-href']\n",
    "\n",
    "# build url from href and base url\n",
    "featured_img_url = f'{base_url}{img_href}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of twitter page to scrape\n",
    "twitter = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# retrieve page with the requests module\n",
    "response = requests.get(twitter)\n",
    "\n",
    "# create bs object; parse with html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all div with class js-tweet-text-container, store them in result set\n",
    "results = soup.find_all('div', class_ = 'js-tweet-text-container')\n",
    "\n",
    "# get the top result (most recent tweet), and pull the text inside the paragraph element\n",
    "mars_weather = results[0].find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of facts page to scrape\n",
    "space_facts = 'https://space-facts.com/mars/'\n",
    "\n",
    "# retrieve page with the requests module\n",
    "response = requests.get(space_facts)\n",
    "\n",
    "# create bs object; parse with html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all tables, store them in result set\n",
    "results = soup.find_all('table')\n",
    "\n",
    "# get the top result, and read the data into a pandas table\n",
    "table = results[0]\n",
    "\n",
    "table = pd.read_html(str(table))\n",
    "\n",
    "# read_html returns a list, use index to store the table as a df\n",
    "mars_facts = table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>0</th>\n",
      "      <td>Equatorial Diameter:</td>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>1</th>\n",
      "      <td>Polar Diameter:</td>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>2</th>\n",
      "      <td>Mass:</td>\n",
      "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>3</th>\n",
      "      <td>Moons:</td>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>4</th>\n",
      "      <td>Orbit Distance:</td>\n",
      "      <td>227,943,824 km (1.38 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>5</th>\n",
      "      <td>Orbit Period:</td>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>6</th>\n",
      "      <td>Surface Temperature:</td>\n",
      "      <td>-87 to -5 °C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>7</th>\n",
      "      <td>First Record:</td>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>8</th>\n",
      "      <td>Recorded By:</td>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "# print out html code for table\n",
    "print(mars_facts.to_html(header = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/speculadora/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/splinter/driver/webdriver/__init__.py:504: FutureWarning: browser.find_link_by_partial_text is deprecated. Use browser.links.find_by_partial_text instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# create list of hemisphere names\n",
    "hemispheres = ['Cerberus',\n",
    "              'Schiaparelli',\n",
    "              'Syrtis Major',\n",
    "              'Valles Marineris']\n",
    "\n",
    "# initialize list to store all hemisphere data\n",
    "hemisphere_data = []\n",
    "\n",
    "for hemisphere in hemispheres:\n",
    "        \n",
    "    # intialize dictionary to store individual hemisphere data\n",
    "    current_hemisphere = {}\n",
    "    \n",
    "    # set starting point\n",
    "    hemisphere_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "    # use splinter to visit url\n",
    "    browser.visit(hemisphere_url)\n",
    "    \n",
    "    # navigate to hemisphere page\n",
    "    browser.click_link_by_partial_text(hemisphere)\n",
    "\n",
    "    # set html from browser\n",
    "    html = browser.html\n",
    "\n",
    "    # create soup object, parse with html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # find div that contains image link, remove it from list\n",
    "    results = soup.find('div', class_ = 'wide-image-wrapper')\n",
    "\n",
    "    # pull the href from the first anchor inside the div to get image link\n",
    "    img_url = results.find('a')['href']\n",
    "    \n",
    "    # find div that contains page title\n",
    "    results = soup.find('div', class_ = 'content')\n",
    "\n",
    "    # pull the text from the header\n",
    "    long_title = results.find('h2').text\n",
    "\n",
    "    # remove 'Enhanced' or 'Unenhanced' from the text\n",
    "    title = long_title.replace(' Enhanced', '')\n",
    "    \n",
    "    # add data to dictionary\n",
    "    current_hemisphere['title'] = title\n",
    "    current_hemisphere['img_url'] = img_url\n",
    "    \n",
    "    hemisphere_data.append(current_hemisphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
